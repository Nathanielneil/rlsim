# SAC Configuration for UAV Navigation  
algorithm: "SAC"
algorithm_params:
  # SAC specific parameters
  learning_rate: 3.0e-4
  buffer_size: 1000000
  batch_size: 256
  gamma: 0.99
  tau: 0.005  # soft update coefficient
  
  # Entropy parameters
  ent_coef: "auto"  # automatic entropy coefficient tuning
  target_entropy: "auto"
  ent_coef_lr: 3.0e-4
  
  # Training parameters
  total_timesteps: 1000000
  train_freq: 1
  gradient_steps: 1
  learning_starts: 10000
  
  # Network architecture
  policy_kwargs:
    net_arch: 
      - 256
      - 256
    activation_fn: "relu"
    log_std_init: -3
    
  # Critic network
  critic_kwargs:
    net_arch:
      - 256  
      - 256
    activation_fn: "relu"
    
  # Target network updates
  target_update_interval: 1
  
  # Optimization
  optimize_memory_usage: true
  create_eval_env: true

# Environment specific settings
env_config:
  action_type: "continuous"  # SAC uses continuous actions
  observation_type: "mixed"   # vision, state, mixed
  
  # Action space bounds
  action_bounds:
    velocity_x: [-5.0, 5.0]
    velocity_y: [-5.0, 5.0]
    velocity_z: [-2.0, 2.0] 
    yaw_rate: [-90.0, 90.0]

# Reward configuration
reward_weights:
  navigation: 1.0
  safety: 1.0
  efficiency: 0.5
  smoothness: 0.3
  collision_penalty: -10.0
  success_reward: 100.0
  
# Training settings
training:
  save_freq: 10000
  eval_freq: 5000
  eval_episodes: 10
  log_interval: 100
  
  # Checkpointing
  checkpoint_freq: 50000
  max_checkpoints: 5
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 100000
    min_delta: 0.01

# Model saving
model_save:
  save_format: "pytorch"
  compress: true
  include_replay_buffer: true  # SAC benefits from saving replay buffer